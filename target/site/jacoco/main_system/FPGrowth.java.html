<?xml version="1.0" encoding="UTF-8"?><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml" lang="zh"><head><meta http-equiv="Content-Type" content="text/html;charset=UTF-8"/><link rel="stylesheet" href="../jacoco-resources/report.css" type="text/css"/><link rel="shortcut icon" href="../jacoco-resources/report.gif" type="image/gif"/><title>FPGrowth.java</title><link rel="stylesheet" href="../jacoco-resources/prettify.css" type="text/css"/><script type="text/javascript" src="../jacoco-resources/prettify.js"></script></head><body onload="window['PR_TAB_WIDTH']=4;prettyPrint()"><div class="breadcrumb" id="breadcrumb"><span class="info"><a href="../jacoco-sessions.html" class="el_session">Sessions</a></span><a href="../index.html" class="el_report">Civil-aviation-recommended-subject</a> &gt; <a href="index.source.html" class="el_package">main_system</a> &gt; <span class="el_source">FPGrowth.java</span></div><h1>FPGrowth.java</h1><pre class="source lang-java linenums">package main_system;

import java.io.*;
import java.util.*;
import java.util.logging.*;

import io.*;
import org.apache.spark.ml.fpm.FPGrowthModel;
import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.types.*;

import static data_processer.DataConverter.*;

public class FPGrowth {
<span class="fc" id="L17">    private static SparkSession spark = null;</span>
    // 最小置信度
    private static float minConfidence;
    // 最小支持度
    private static float minSupport;
    //csv文件结果输出目录路径，若是不以csv文件的格式输出，则该属性可以为null
    private static String resultDirPath;
    // 机票订单csv文件路径
    private static String pathT;
    // 酒店订单csv文件路径
    private static String pathH;
    // 餐饮订单csv文件路径
    private static String pathM;
    // 保险订单csv文件路径
    private static String pathB;
    // 保险订单csv文件路径
    private static String pathI;
    // 选座订单csv文件路径
    private static String pathS;
    // 模式(若是debug模式，则会输出一部分频繁项集和关联规则，否则不输出)
    private static String mode;
    // 结果输出格式（可以是csv或者是db），csv则会将结果以csv文件的形式输出，db则会将结果存入数据库中
    private static String resultForm;
    // 训练备注
    private static String comment;
<span class="fc" id="L42">    private static Logger logger = null;</span>
    //spark是否已经初始化
<span class="fc" id="L44">    private static boolean isSparkInitialed =false;</span>
    // csv文件输入输出工具类
<span class="fc" id="L46">    private static CSVFileIO fileIO = null;</span>

    private FPGrowth() {
    }

    public static void initializeSpark() {
        // 判断是否已经初始化
<span class="fc bfc" id="L53" title="All 2 branches covered.">        if(isSparkInitialed){</span>
<span class="fc" id="L54">            return;</span>
        }
        // 创建SparkSession对象
        spark = SparkSession
<span class="fc" id="L58">                .builder()</span>
<span class="fc" id="L59">                .appName(&quot;Civil-aviation-recommended-subject&quot;)</span>
                //设置本地运行以及线程数量最大值（local含义为本地运行，*表示线程数量尽可能多）
<span class="fc" id="L61">                .master(&quot;local[*]&quot;)</span>
<span class="fc" id="L62">                .getOrCreate();</span>

        // 创建日志对象
<span class="fc" id="L65">        logger = Logger.getLogger(FPGrowth.class.getName());</span>

        //读取配置文件
<span class="fc" id="L68">        readProperties();</span>

<span class="fc" id="L70">        isSparkInitialed = true;</span>
<span class="fc" id="L71">    }</span>

    private static void readProperties() {
        // 创建Properties对象
<span class="fc" id="L75">        Properties properties = new Properties();</span>
        // 读取配置文件
        try {
<span class="fc" id="L78">            InputStream stream = MongoUtils.class.getClassLoader().getResourceAsStream(&quot;System.properties&quot;);</span>
<span class="fc" id="L79">            properties.load(stream);</span>
<span class="nc" id="L80">        } catch (IOException e) {</span>
<span class="nc" id="L81">            logger.info(&quot;加载配置文件失败&quot;);</span>
<span class="fc" id="L82">        }</span>
        // 获取配置文件中的属性
        // 获取csv文件结果输出目录，若是不以csv文件的格式输出，则该属性可以为null
<span class="fc" id="L85">        resultDirPath = properties.getProperty(&quot;resultDirPath&quot;);</span>
        // 获取机票订单csv文件路径
<span class="fc" id="L87">        pathT = properties.getProperty(&quot;ticketFilePath&quot;);</span>
        // 获取酒店订单csv文件路径
<span class="fc" id="L89">        pathH = properties.getProperty(&quot;hotelFilePath&quot;);</span>
        // 获取餐饮订单csv文件路径
<span class="fc" id="L91">        pathM = properties.getProperty(&quot;mealFilePath&quot;);</span>
        // 获取保险订单csv文件路径
<span class="fc" id="L93">        pathB = properties.getProperty(&quot;baggageFilePath&quot;);</span>
        // 获取保险订单csv文件路径
<span class="fc" id="L95">        pathI = properties.getProperty(&quot;insuranceFilePath&quot;);</span>
        // 获取选座订单csv文件路径
<span class="fc" id="L97">        pathS = properties.getProperty(&quot;seatFilePath&quot;);</span>
        // 获取模式(若是debug模式，则会输出一部分频繁项集和关联规则，否则不输出)
<span class="fc" id="L99">        mode = properties.getProperty(&quot;mode&quot;);</span>
        // 获取结果输出格式
<span class="fc" id="L101">        resultForm = properties.getProperty(&quot;resultForm&quot;);</span>
        // 获取最小置信度
<span class="pc bpc" id="L103" title="1 of 2 branches missed.">        minConfidence = properties.getProperty(&quot;minConfidence&quot;) != null ? Float.parseFloat(properties.getProperty(&quot;minConfidence&quot;)) : 0;</span>
        // 获取最小支持度
<span class="pc bpc" id="L105" title="1 of 2 branches missed.">        minSupport = properties.getProperty(&quot;minSupport&quot;) != null ? Float.parseFloat(properties.getProperty(&quot;minSupport&quot;)) : 0;</span>
        // 获取训练备注
<span class="fc" id="L107">        comment = properties.getProperty(&quot;comment&quot;);</span>
<span class="fc" id="L108">    }</span>

    /**
     * 训练FPGrowth模型
     * @param itemsDF 输入机票和商品属性订单共现数据
     * @return 返回训练好的FPGrowth模型
     */
    public static FPGrowthModel train(Dataset&lt;Row&gt; itemsDF) {
<span class="fc" id="L116">        logger.info(&quot;正在使用FPGrowth算法训练模型&quot;);</span>
<span class="fc" id="L117">        return new org.apache.spark.ml.fpm.FPGrowth()</span>
<span class="fc" id="L118">                .setItemsCol(&quot;items&quot;)//设置items列名</span>
<span class="fc" id="L119">                .setMinSupport(minSupport)//最小支持度</span>
<span class="fc" id="L120">                .setMinConfidence(minConfidence)//最小置信度</span>
<span class="fc" id="L121">                .fit(itemsDF);//让模型适应输入数据</span>
    }

    /**
     * 由输入的机票和商品属性订单共现数据训练，可选择是否输出频繁项集和关联规则
     * @param sourceData 输入机票和商品属性订单共现数据
     * @param outPutFrequentItems 是否输出频繁项集
     * @param outPutRules   是否输出关联规则
     * @param frqItemSetsList   频繁项集List
     * @param rulesList 关联规则List
     */
    public static void singleTypeMining(Dataset&lt;Row&gt; sourceData,boolean outPutFrequentItems,boolean outPutRules
            ,List&lt;List&lt;String&gt;&gt; frqItemSetsList,List&lt;List&lt;String&gt;&gt; rulesList){
        // 启动SparkSession
<span class="fc" id="L135">        initializeSpark();</span>
        //从sourceData中训练模型
<span class="fc" id="L137">        FPGrowthModel model = train(sourceData);</span>
        // 从两个boolean参数中判断是否挖掘频繁项集和关联规则并输出
<span class="fc bfc" id="L139" title="All 2 branches covered.">        if(outPutFrequentItems){</span>
            // 得到频繁项集
<span class="fc" id="L141">            Dataset&lt;Row&gt; freqItemSets = model.freqItemsets();</span>
            //将频繁项集转换为List&lt;List&lt;String&gt;&gt;
<span class="fc" id="L143">            dataset2FRList(freqItemSets,frqItemSetsList);</span>
        }
<span class="fc bfc" id="L145" title="All 2 branches covered.">        if(outPutRules){</span>
            // 得到关联规则
<span class="fc" id="L147">            Dataset&lt;Row&gt; rules = model.associationRules();</span>
            //将关联规则转换为List&lt;List&lt;String&gt;&gt;
<span class="fc" id="L149">            dataset2RulesList(rules,rulesList);</span>
        }
<span class="fc" id="L151">    }</span>

    public static void initializeFileIO() throws IOException {
<span class="fc bfc" id="L154" title="All 2 branches covered.">        if(fileIO!=null){</span>
<span class="fc" id="L155">            return;</span>
        }
        // 创建CSVFileIO对象
<span class="fc" id="L158">        fileIO = new CSVFileIO(resultDirPath, pathT, pathH, pathM, pathB, pathI, pathS);</span>
<span class="fc" id="L159">    }</span>

    public static void fpGrowthTest() throws IOException{
        // 启动SparkSession
<span class="nc" id="L163">        initializeSpark();</span>
        // 创建数据转换器对象
<span class="nc" id="L165">        initializeFileIO();</span>
<span class="nc bnc" id="L166" title="All 2 branches missed.">        for (int i = 1; i &lt; 6; i++) {</span>

            // 准备数据
<span class="nc" id="L169">            logger.info(&quot;正在准备数据&quot;);</span>
<span class="nc" id="L170">            Dataset&lt;Row&gt; itemsDF = fileIO.singelTypeCsv2dataset(i);</span>

            // 使用FPGrowth算法训练模型
<span class="nc" id="L173">            FPGrowthModel model = train(itemsDF);</span>

            // 得到频繁项集
<span class="nc" id="L176">            Dataset&lt;Row&gt; freqItemSets = model.freqItemsets();</span>

            // 可以选择显示频繁项集(freqItemSets.show();)
<span class="nc bnc" id="L179" title="All 2 branches missed.">            if (mode.equals(&quot;debug&quot;)) {</span>
<span class="nc" id="L180">                logger.info(&quot;显示频繁项集&quot;);</span>
<span class="nc" id="L181">                freqItemSets.show();</span>
            }



            //保存频繁项集到csv
<span class="nc bnc" id="L187" title="All 2 branches missed.">            if (resultForm.equals(&quot;csv&quot;)) {</span>
<span class="nc" id="L188">                fileIO.freItemSet2CSV(freqItemSets, i);</span>
<span class="nc bnc" id="L189" title="All 2 branches missed.">            }else if (resultForm.equals(&quot;db&quot;)) {</span>
<span class="nc" id="L190">                MongoUtils.frequentItemSets2db(freqItemSets, i);</span>
            }

            // 显示生成的关联规则并保存到csv
<span class="nc" id="L194">            Dataset&lt;Row&gt; rules = model.associationRules();</span>
<span class="nc bnc" id="L195" title="All 2 branches missed.">            if (mode.equals(&quot;debug&quot;)) {</span>
<span class="nc" id="L196">                logger.info(&quot;显示关联规则&quot;);</span>
<span class="nc" id="L197">                rules.show();</span>
            }

<span class="nc bnc" id="L200" title="All 2 branches missed.">            if (resultForm.equals(&quot;csv&quot;)) {</span>
                //保存关联规则到csv
<span class="nc" id="L202">                fileIO.rules2CSV(rules, i);</span>
<span class="nc bnc" id="L203" title="All 2 branches missed.">            } else if (resultForm.equals(&quot;db&quot;)) {</span>
                //保存关联规则到数据库
<span class="nc" id="L205">                MongoUtils.rules2db(rules, i);</span>
            }
        }

        // 停止SparkSession
<span class="nc" id="L210">        logger.info(&quot;SparkSession停止&quot;);</span>
        //停止MongoDB
<span class="nc" id="L212">        MongoUtils.closeMongoClient(fileIO.getOrderNumber(),comment,minSupport);</span>
<span class="nc" id="L213">        spark.stop();</span>
<span class="nc" id="L214">    }</span>

    /**
     * 定义数据模式
     * @return 返回定义好的特定数据模式
     */
    public static StructType getSchema() {
        // 定义数据模式
<span class="fc" id="L222">        logger.info(&quot;正在定义数据模式&quot;);</span>
<span class="fc" id="L223">        return new StructType(new StructField[]{new StructField(</span>
                &quot;items&quot;,
                new ArrayType(DataTypes.StringType, true)
                //该字段名称为items，元素类型为String
                , false,//false表示该字段不能为空
<span class="fc" id="L228">                Metadata.empty())//无附加元数据</span>

        });
    }

    public static Dataset&lt;Row&gt; getDataFrame(List&lt;Row&gt; data) {
<span class="fc" id="L234">        return spark.createDataFrame(data, getSchema());</span>
    }

    public static CSVFileIO getFileIO() {
        // 返回CSVFileIO对象
<span class="fc" id="L239">        return fileIO;</span>
    }

}
</pre><div class="footer"><span class="right">Created with <a href="http://www.jacoco.org/jacoco">JaCoCo</a> 0.8.7.202105040129</span></div></body></html>